FROM apache/airflow:2.8.2

USER root

# Install Java (required for spark-submit), git (for DVC), and utilities
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    openjdk-17-jre-headless \
    wget \
    procps \
    git \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME dynamically based on architecture
RUN ARCH=$(dpkg --print-architecture) && \
    echo "JAVA_HOME=/usr/lib/jvm/java-17-openjdk-${ARCH}" >> /etc/environment && \
    echo "export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-${ARCH}" >> /etc/profile

# For Docker build, set a default (will be overridden at runtime via /etc/environment)
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:${PATH}"

# Download Spark (client only - for spark-submit command)
ENV SPARK_VERSION=3.4.1
ENV SPARK_HOME=/opt/spark
ENV PATH="${SPARK_HOME}/bin:${PATH}"

RUN wget -q "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop3.tgz" && \
    tar xzf "spark-${SPARK_VERSION}-bin-hadoop3.tgz" -C /opt && \
    mv "/opt/spark-${SPARK_VERSION}-bin-hadoop3" "${SPARK_HOME}" && \
    rm "spark-${SPARK_VERSION}-bin-hadoop3.tgz"

# Configure Spark with dynamic JAVA_HOME detection
RUN ARCH=$(dpkg --print-architecture) && \
    echo "export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-${ARCH}" > ${SPARK_HOME}/conf/spark-env.sh && \
    chmod +x ${SPARK_HOME}/conf/spark-env.sh

# Download AWS/S3 JARs for MinIO connectivity
RUN cd ${SPARK_HOME}/jars && \
    wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar && \
    wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar

USER airflow

# Install Airflow Spark provider and Python dependencies
RUN pip install --no-cache-dir \
    apache-airflow-providers-apache-spark>=4.8.0 \
    boto3>=1.34.0 \
    pydantic>=2.5.0 \
    pydantic-settings>=2.1.0 \
    PyYAML>=6.0.1 \
    dvc[s3]>=3.30.0 \
    psycopg2-binary>=2.9.9 \
    pyspark==3.4.1 \
    pandas>=2.1.0 \
    numpy>=1.26.0 \
    s3fs>=2024.2.0 \
    pyarrow>=14.0.0
